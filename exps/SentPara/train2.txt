Script started on Sun 21 Apr 2019 04:28:58 PM EDT
[01;32mcxing95@speech10[00m:[01;34m~/4080/RL-for-QA[00m$ exitpython train_SentPara.py [15Pnvidia-smipython train_SentPara.py 
NN structure: 
SentParaNN(
  (lstm): LSTM(1024, 1024, num_layers=2, batch_first=True, bidirectional=True)
  (paraNN): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
  (sentNN): Sequential(
    (0): Linear(in_features=2048, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=2, bias=True)
  )
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (para_softmax): Softmax()
  (sent_softmax): Softmax()
)
Epoch 1/20
--------------------
Epoch 1 Iteration 0: running_corrects: 68 running loss = 46755.148438
Traceback (most recent call last):
  File "train_SentPara.py", line 115, in <module>
    s_out, p_out = model(sents, para)
  File "/home/cxing95/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cxing95/4080/RL-for-QA/NNetworks.py", line 98, in forward
    sents_out, _ = self.lstm(sents)
  File "/home/cxing95/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py", line 477, in __call__
    result = self.forward(*input, **kwargs)
  File "/home/cxing95/anaconda3/lib/python3.6/site-packages/torch/nn/modules/rnn.py", line 192, in forward
    output, hidden = func(input, self.all_weights, hx, batch_sizes)
  File "/home/cxing95/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py", line 324, in forward
    return func(input, *fargs, **fkwargs)
  File "/home/cxing95/anaconda3/lib/python3.6/site-packages/torch/nn/_functions/rnn.py", line 288, in forward
    dropout_ts)
RuntimeError: CUDA error: out of memory
[01;32mcxing95@speech10[00m:[01;34m~/4080/RL-for-QA[00m$ python train_SentPara.py 
NN structure: 
SentParaNN(
  (lstm): LSTM(1024, 1024, num_layers=2, batch_first=True, bidirectional=True)
  (paraNN): Sequential(
    (0): Linear(in_features=1024, out_features=512, bias=True)
    (1): ReLU()
    (2): Linear(in_features=512, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=2, bias=True)
  )
  (sentNN): Sequential(
    (0): Linear(in_features=2048, out_features=1024, bias=True)
    (1): ReLU()
    (2): Linear(in_features=1024, out_features=512, bias=True)
    (3): ReLU()
    (4): Linear(in_features=512, out_features=2, bias=True)
  )
  (relu): ReLU()
  (sigmoid): Sigmoid()
  (para_softmax): Softmax()
  (sent_softmax): Softmax()
)
Epoch 1/20
--------------------
Epoch 1 Iteration 0: running_corrects: 4041 running loss = 43868.777344
Epoch 1 Iteration 50: running_corrects: 238330 running loss = 265143.671753
Epoch 1 Iteration 100: running_corrects: 501750 running loss = 416242.781372
Epoch 1 Iteration 150: running_corrects: 728545 running loss = 570384.293091
Epoch 1 Iteration 200: running_corrects: 983485 running loss = 719099.669128
Epoch 1 Iteration 250: running_corrects: 1223560 running loss = 870307.662903
Epoch 1 Iteration 300: running_corrects: 1489926 running loss = 1004996.609985
Epoch 1 Iteration 350: running_corrects: 1766339 running loss = 1137134.803101
Epoch 1 Iteration 400: running_corrects: 2009320 running loss = 1279518.929443
Epoch 1 Iteration 450: running_corrects: 2243680 running loss = 1421397.951416
Epoch 1 Iteration 500: running_corrects: 2524062 running loss = 1555427.096802
Epoch 1 Iteration 550: running_corrects: 2794441 running loss = 1693527.156189
Epoch 1 Iteration 600: running_corrects: 3047401 running loss = 1835244.389771
Epoch 1 Iteration 650: running_corrects: 3279740 running loss = 1975411.740295
Epoch 1 Iteration 700: running_corrects: 3588927 running loss = 2098557.833496
Epoch 1 Iteration 750: running_corrects: 3865038 running loss = 2237533.774658
train Loss: 11.5743 Acc: 20.0493 F1: 0.1110
 
Epoch 1 Iteration 0: running_corrects: 8156 running loss = 1033.038696
Epoch 1 Iteration 50: running_corrects: 277970 running loss = 102182.322327
Epoch 1 Iteration 100: running_corrects: 529657 running loss = 204993.747925
Epoch 1 Iteration 150: running_corrects: 805863 running loss = 302422.711670
Epoch 1 Iteration 200: running_corrects: 1114630 running loss = 392888.547333
Epoch 1 Iteration 250: running_corrects: 1374687 running loss = 492273.280029
dev Loss: 7.6894 Acc: 20.9317 F1: 0.0964
 
Epoch 2/20
--------------------
Epoch 2 Iteration 0: running_corrects: 4301 running loss = 2377.916504
Epoch 2 Iteration 50: running_corrects: 252677 running loss = 134232.774170
Epoch 2 Iteration 100: running_corrects: 510178 running loss = 261309.878845
Epoch 2 Iteration 150: running_corrects: 766697 running loss = 394805.876770
Epoch 2 Iteration 200: running_corrects: 1033852 running loss = 521184.513916
Epoch 2 Iteration 250: running_corrects: 1290645 running loss = 647466.569153
Epoch 2 Iteration 300: running_corrects: 1585678 running loss = 759889.362061
Epoch 2 Iteration 350: running_corrects: 1856990 running loss = 884369.024902
Epoch 2 Iteration 400: running_corrects: 2099764 running loss = 1020589.255249
Epoch 2 Iteration 450: running_corrects: 2369878 running loss = 1143510.840576
Epoch 2 Iteration 500: running_corrects: 2616141 running loss = 1269265.954346
Epoch 2 Iteration 550: running_corrects: 2862675 running loss = 1402258.324524
Epoch 2 Iteration 600: running_corrects: 3149580 running loss = 1524830.456970
Epoch 2 Iteration 650: running_corrects: 3374331 running loss = 1667626.154480
Epoch 2 Iteration 700: running_corrects: 3627172 running loss = 1799211.299683
Epoch 2 Iteration 750: running_corrects: 3898245 running loss = 1926630.035706
train Loss: 10.0369 Acc: 20.1519 F1: 0.2284
 
Epoch 2 Iteration 0: running_corrects: 8158 running loss = 990.784363
Epoch 2 Iteration 50: running_corrects: 277951 running loss = 98096.805542
Epoch 2 Iteration 100: running_corrects: 529599 running loss = 197356.980438
Epoch 2 Iteration 150: running_corrects: 805772 running loss = 291169.931183
Epoch 2 Iteration 200: running_corrects: 1114512 running loss = 378578.713501
Epoch 2 Iteration 250: running_corrects: 1374531 running loss = 475201.927704
dev Loss: 7.4221 Acc: 20.9292 F1: 0.1721
 
Epoch 3/20
--------------------
Epoch 3 Iteration 0: running_corrects: 3775 running loss = 3359.599854
Epoch 3 Iteration 50: running_corrects: 269303 running loss = 118589.141968
Epoch 3 Iteration 100: running_corrects: 523808 running loss = 236568.486511
Epoch 3 Iteration 150: running_corrects: 800494 running loss = 357489.092102
Epoch 3 Iteration 200: running_corrects: 1091366 running loss = 469461.127563
Epoch 3 Iteration 250: running_corrects: 1348440 running loss = 585635.377991
Epoch 3 Iteration 300: running_corrects: 1574784 running loss = 717102.850891
Epoch 3 Iteration 350: running_corrects: 1816698 running loss = 841511.159424
Epoch 3 Iteration 400: running_corrects: 2088623 running loss = 962442.370544
Epoch 3 Iteration 450: running_corrects: 2339533 running loss = 1085304.768555
Epoch 3 Iteration 500: running_corrects: 2587728 running loss = 1207339.472778
Epoch 3 Iteration 550: running_corrects: 2836907 running loss = 1329754.093750
Epoch 3 Iteration 600: running_corrects: 3086816 running loss = 1452666.067383
Epoch 3 Iteration 650: running_corrects: 3329571 running loss = 1575986.572144
Epoch 3 Iteration 700: running_corrects: 3592048 running loss = 1702372.041138
Epoch 3 Iteration 750: running_corrects: 3856955 running loss = 1825403.515320
train Loss: 9.4591 Acc: 20.1633 F1: 0.2822
 
Epoch 3 Iteration 0: running_corrects: 8156 running loss = 952.771057
Epoch 3 Iteration 50: running_corrects: 277983 running loss = 93517.332977
Epoch 3 Iteration 100: running_corrects: 529678 running loss = 188171.233246
Epoch 3 Iteration 150: running_corrects: 805878 running loss = 277964.089722
Epoch 3 Iteration 200: running_corrects: 1114644 running loss = 361084.140839
Epoch 3 Iteration 250: running_corrects: 1374664 running loss = 453114.106537
dev Loss: 7.0824 Acc: 20.9314 F1: 0.1813
 
Epoch 4/20
--------------------
Epoch 4 Iteration 0: running_corrects: 6851 running loss = 1660.806030
Epoch 4 Iteration 50: running_corrects: 297776 running loss = 112756.092346
Epoch 4 Iteration 100: running_corrects: 561813 running loss = 222100.185547
Epoch 4 Iteration 150: running_corrects: 793454 running loss = 338222.959900
Epoch 4 Iteration 200: running_corrects: 1053151 running loss = 454007.421753
Epoch 4 Iteration 250: running_corrects: 1302614 running loss = 566083.160522
Epoch 4 Iteration 300: running_corrects: 1544730 running loss = 676775.935425
Epoch 4 Iteration 350: running_corrects: 1793948 running loss = 788297.597900
Epoch 4 Iteration 400: running_corrects: 2018079 running loss = 909795.259888
Epoch 4 Iteration 450: running_corrects: 2291399 running loss = 1019068.629456
Epoch 4 Iteration 500: running_corrects: 2542934 running loss = 1132820.147461
Epoch 4 Iteration 550: running_corrects: 2793592 running loss = 1249266.881653
Epoch 4 Iteration 600: running_corrects: 3071791 running loss = 1353852.972046
Epoch 4 Iteration 650: running_corrects: 3345933 running loss = 1456698.160858
Epoch 4 Iteration 700: running_corrects: 3602045 running loss = 1569943.468536
Epoch 4 Iteration 750: running_corrects: 3850267 running loss = 1681920.211945
train Loss: 8.6972 Acc: 20.2961 F1: 0.3446
 
Epoch 4 Iteration 0: running_corrects: 8159 running loss = 925.976501
Epoch 4 Iteration 50: running_corrects: 277841 running loss = 96421.396240
Epoch 4 Iteration 100: running_corrects: 529356 running loss = 193360.928223
Epoch 4 Iteration 150: running_corrects: 805384 running loss = 285290.819702
Epoch 4 Iteration 200: running_corrects: 1114053 running loss = 370642.313477
Epoch 4 Iteration 250: running_corrects: 1373945 running loss = 464872.955200
dev Loss: 7.2613 Acc: 20.9204 F1: 0.2613
 
Epoch 5/20
--------------------
Epoch 5 Iteration 0: running_corrects: 6076 running loss = 1913.879028
Epoch 5 Iteration 50: running_corrects: 298460 running loss = 99809.376831
Epoch 5 Iteration 100: running_corrects: 550930 running loss = 202196.392059
Epoch 5 Iteration 150: running_corrects: 784701 running loss = 312454.988068
Epoch 5 Iteration 200: running_corrects: 1071455 running loss = 416122.690582
Epoch 5 Iteration 250: running_corrects: 1363366 running loss = 513152.873810
Epoch 5 Iteration 300: running_corrects: 1590022 running loss = 617023.856110
Epoch 5 Iteration 350: running_corrects: 1853253 running loss = 715620.902802
Epoch 5 Iteration 400: running_corrects: 2131037 running loss = 814109.259796
Epoch 5 Iteration 450: running_corrects: 2367138 running loss = 916570.704376
Epoch 5 Iteration 500: running_corrects: 2650725 running loss = 1012388.122650
Epoch 5 Iteration 550: running_corrects: 2911173 running loss = 1117259.252197
Epoch 5 Iteration 600: running_corrects: 3183827 running loss = 1216705.504578
Epoch 5 Iteration 650: running_corrects: 3406447 running loss = 1334220.411377
Epoch 5 Iteration 700: running_corrects: 3641372 running loss = 1442894.117554
Epoch 5 Iteration 750: running_corrects: 3880071 running loss = 1546069.014526
train Loss: 8.0726 Acc: 20.0666 F1: 0.4297
 
Epoch 5 Iteration 0: running_corrects: 8154 running loss = 996.204468
Epoch 5 Iteration 50: running_corrects: 277463 running loss = 99479.034180
Epoch 5 Iteration 100: running_corrects: 528616 running loss = 201325.784882
Epoch 5 Iteration 150: running_corrects: 804315 running loss = 297661.220093
Epoch 5 Iteration 200: running_corrects: 1112653 running loss = 385616.667786
Epoch 5 Iteration 250: running_corrects: 1372220 running loss = 482765.089081
dev Loss: 7.5554 Acc: 20.8930 F1: 0.3042
 
Epoch 6/20
--------------------
Epoch 6 Iteration 0: running_corrects: 3015 running loss = 3203.544434
Epoch 6 Iteration 50: running_corrects: 241656 running loss = 98714.968475
Epoch 6 Iteration 100: running_corrects: 477585 running loss = 188508.932281
Epoch 6 Iteration 150: running_corrects: 745091 running loss = 282570.942871
Epoch 6 Iteration 200: running_corrects: 975284 running loss = 374345.201050
Epoch 6 Iteration 250: running_corrects: 1250155 running loss = 465479.562073
Epoch 6 Iteration 300: running_corrects: 1517584 running loss = 555725.130371
Epoch 6 Iteration 350: running_corrects: 1800454 running loss = 647548.615753
Epoch 6 Iteration 400: running_corrects: 2023395 running loss = 743747.272614
Epoch 6 Iteration 450: running_corrects: 2288065 running loss = 832368.271698
Epoch 6 Iteration 500: running_corrects: 2525074 running loss = 932407.441498
Epoch 6 Iteration 550: running_corrects: 2797957 running loss = 1023025.186279
Epoch 6 Iteration 600: running_corrects: 3059535 running loss = 1114162.537537
Epoch 6 Iteration 650: running_corrects: 3345003 running loss = 1199673.366760
Epoch 6 Iteration 700: running_corrects: 3616140 running loss = 1291261.459534
Epoch 6 Iteration 750: running_corrects: 3875967 running loss = 1381933.259460
train Loss: 7.1644 Acc: 20.1646 F1: 0.5210
 
Epoch 6 Iteration 0: running_corrects: 8157 running loss = 875.943054
Epoch 6 Iteration 50: running_corrects: 277550 running loss = 100007.616791
Epoch 6 Iteration 100: running_corrects: 528823 running loss = 200872.497101
Epoch 6 Iteration 150: running_corrects: 804577 running loss = 296070.596283
Epoch 6 Iteration 200: running_corrects: 1113016 running loss = 383836.092072
Epoch 6 Iteration 250: running_corrects: 1372627 running loss = 481044.886505
dev Loss: 7.5019 Acc: 20.9003 F1: 0.3142
 
Epoch 7/20
--------------------
Epoch 7 Iteration 0: running_corrects: 5583 running loss = 1476.623047
Epoch 7 Iteration 50: running_corrects: 287148 running loss = 72868.141296
Epoch 7 Iteration 100: running_corrects: 554841 running loss = 143000.889160
Epoch 7 Iteration 150: running_corrects: 771337 running loss = 224098.895874
Epoch 7 Iteration 200: running_corrects: 1021559 running loss = 295419.859192
Epoch 7 Iteration 250: running_corrects: 1253757 running loss = 376597.524719
Epoch 7 Iteration 300: running_corrects: 1495703 running loss = 454883.811157
Epoch 7 Iteration 350: running_corrects: 1791713 running loss = 526452.487213
Epoch 7 Iteration 400: running_corrects: 2033776 running loss = 606270.205719
Epoch 7 Iteration 450: running_corrects: 2315384 running loss = 682284.762726
Epoch 7 Iteration 500: running_corrects: 2571126 running loss = 762987.592896
Epoch 7 Iteration 550: running_corrects: 2797927 running loss = 846645.376343
Epoch 7 Iteration 600: running_corrects: 3045695 running loss = 928531.155884
Epoch 7 Iteration 650: running_corrects: 3295546 running loss = 1009184.514923
Epoch 7 Iteration 700: running_corrects: 3560325 running loss = 1084022.544098
Epoch 7 Iteration 750: running_corrects: 3846474 running loss = 1164610.582520
train Loss: 6.0435 Acc: 20.0745 F1: 0.6210
 
Epoch 7 Iteration 0: running_corrects: 8150 running loss = 979.573853
Epoch 7 Iteration 50: running_corrects: 277500 running loss = 102895.934967
Epoch 7 Iteration 100: running_corrects: 528707 running loss = 209664.044647
Epoch 7 Iteration 150: running_corrects: 804426 running loss = 310049.093842
Epoch 7 Iteration 200: running_corrects: 1112769 running loss = 400886.410736
Epoch 7 Iteration 250: running_corrects: 1372349 running loss = 502097.893036
dev Loss: 7.8361 Acc: 20.8952 F1: 0.3130
 
Epoch 8/20
--------------------
Epoch 8 Iteration 0: running_corrects: 3557 running loss = 1372.260376
Epoch 8 Iteration 50: running_corrects: 274446 running loss = 60788.421021
Epoch 8 Iteration 100: running_corrects: 494598 running loss = 126129.406555
Epoch 8 Iteration 150: running_corrects: 775387 running loss = 183261.784790
Epoch 8 Iteration 200: running_corrects: 1036165 running loss = 244184.848480
Epoch 8 Iteration 250: running_corrects: 1318361 running loss = 307585.591339
Epoch 8 Iteration 300: running_corrects: 1550451 running loss = 374923.264374
Epoch 8 Iteration 350: running_corrects: 1821958 running loss = 438539.911774
Epoch 8 Iteration 400: running_corrects: 2063843 running loss = 502067.109344
Epoch 8 Iteration 450: running_corrects: 2331690 running loss = 568175.621246
Epoch 8 Iteration 500: running_corrects: 2631079 running loss = 630041.686005
Epoch 8 Iteration 550: running_corrects: 2882107 running loss = 695602.986969
Epoch 8 Iteration 600: running_corrects: 3107499 running loss = 763710.888641
Epoch 8 Iteration 650: running_corrects: 3336698 running loss = 832498.885345
Epoch 8 Iteration 700: running_corrects: 3577931 running loss = 900324.147858
Epoch 8 Iteration 750: running_corrects: 3856517 running loss = 965170.637329
train Loss: 5.0230 Acc: 20.2435 F1: 0.7041
 
Epoch 8 Iteration 0: running_corrects: 8149 running loss = 1089.874390
Epoch 8 Iteration 50: running_corrects: 277186 running loss = 115662.842163
Epoch 8 Iteration 100: running_corrects: 528126 running loss = 236254.507751
Epoch 8 Iteration 150: running_corrects: 803543 running loss = 349518.084351
Epoch 8 Iteration 200: running_corrects: 1111580 running loss = 453319.427734
Epoch 8 Iteration 250: running_corrects: 1370917 running loss = 565838.138672
dev Loss: 8.8250 Acc: 20.8739 F1: 0.3264
 
Epoch 9/20
--------------------
Epoch 9 Iteration 0: running_corrects: 4070 running loss = 1082.084961
Epoch 9 Iteration 50: running_corrects: 242270 running loss = 49855.005737
Epoch 9 Iteration 100: running_corrects: 505580 running loss = 97748.216827
Epoch 9 Iteration 150: running_corrects: 734268 running loss = 148450.855682
Epoch 9 Iteration 200: running_corrects: 998231 running loss = 196583.499115
Epoch 9 Iteration 250: running_corrects: 1246290 running loss = 248163.985352
Epoch 9 Iteration 300: running_corrects: 1556795 running loss = 295809.886322
Epoch 9 Iteration 350: running_corrects: 1833291 running loss = 344926.088989
Epoch 9 Iteration 400: running_corrects: 2104080 running loss = 397743.533630
Epoch 9 Iteration 450: running_corrects: 2365156 running loss = 449358.199524
Epoch 9 Iteration 500: running_corrects: 2610536 running loss = 503292.303375
Epoch 9 Iteration 550: running_corrects: 2843879 running loss = 562029.623993
Epoch 9 Iteration 600: running_corrects: 3114890 running loss = 616851.968781
Epoch 9 Iteration 650: running_corrects: 3365678 running loss = 669902.893921
Epoch 9 Iteration 700: running_corrects: 3617701 running loss = 724214.461823
Epoch 9 Iteration 750: running_corrects: 3908662 running loss = 776831.704376
train Loss: 4.0481 Acc: 20.3762 F1: 0.7732
 
Epoch 9 Iteration 0: running_corrects: 8146 running loss = 1236.339600
Epoch 9 Iteration 50: running_corrects: 277228 running loss = 137919.799683
Epoch 9 Iteration 100: running_corrects: 528157 running loss = 281082.074951
Epoch 9 Iteration 150: running_corrects: 803596 running loss = 416496.578674
Epoch 9 Iteration 200: running_corrects: 1111659 running loss = 539182.182495
Epoch 9 Iteration 250: running_corrects: 1370938 running loss = 671454.778992
^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[A^[[Adev Loss: 10.4383 Acc: 20.8744 F1: 0.3176
 
Epoch 10/20
--------------------
Epoch 10 Iteration 0: running_corrects: 10738 running loss = 333.918274
Epoch 10 Iteration 50: running_corrects: 289861 running loss = 39596.549423
Epoch 10 Iteration 100: running_corrects: 555942 running loss = 79539.131485
Epoch 10 Iteration 150: running_corrects: 775345 running loss = 123018.892197
Epoch 10 Iteration 200: running_corrects: 1034460 running loss = 162034.986343
Epoch 10 Iteration 250: running_corrects: 1293812 running loss = 203206.464935
Epoch 10 Iteration 300: running_corrects: 1535680 running loss = 247403.966919
Epoch 10 Iteration 350: running_corrects: 1806227 running loss = 289654.345856
Epoch 10 Iteration 400: running_corrects: 2036829 running loss = 334648.917694
Epoch 10 Iteration 450: running_corrects: 2314058 running loss = 373542.662659
Epoch 10 Iteration 500: running_corrects: 2598419 running loss = 417642.551346
Epoch 10 Iteration 550: running_corrects: 2857190 running loss = 460607.060104
Epoch 10 Iteration 600: running_corrects: 3086166 running loss = 510123.007339
Epoch 10 Iteration 650: running_corrects: 3367177 running loss = 551700.991379
Epoch 10 Iteration 700: running_corrects: 3613409 running loss = 595708.055313
Epoch 10 Iteration 750: running_corrects: 3869523 running loss = 642815.168976
train Loss: 3.3607 Acc: 20.1564 F1: 0.8223
 
Epoch 10 Iteration 0: running_corrects: 8147 running loss = 1317.958496
Epoch 10 Iteration 50: running_corrects: 277153 running loss = 146053.010254
Epoch 10 Iteration 100: running_corrects: 528011 running loss = 295005.333069
Epoch 10 Iteration 150: running_corrects: 803429 running loss = 438346.330688
Epoch 10 Iteration 200: running_corrects: 1111543 running loss = 565979.160278
Epoch 10 Iteration 250: running_corrects: 1370863 running loss = 704021.665527
dev Loss: 10.9766 Acc: 20.8727 F1: 0.3199
 
Epoch 11/20
--------------------
Epoch 11 Iteration 0: running_corrects: 3827 running loss = 698.962036
Epoch 11 Iteration 50: running_corrects: 259987 running loss = 27943.585144
Epoch 11 Iteration 100: running_corrects: 494515 running loss = 60446.157959
Epoch 11 Iteration 150: running_corrects: 721371 running loss = 94711.194946
Epoch 11 Iteration 200: running_corrects: 980968 running loss = 126683.860870
Epoch 11 Iteration 250: running_corrects: 1211123 running loss = 160560.427551
Epoch 11 Iteration 300: running_corrects: 1458561 running loss = 197563.649124
Epoch 11 Iteration 350: running_corrects: 1722417 running loss = 232502.264206
Epoch 11 Iteration 400: running_corrects: 1958281 running loss = 272079.079147
Epoch 11 Iteration 450: running_corrects: 2233117 running loss = 308032.918289
Epoch 11 Iteration 500: running_corrects: 2452962 running loss = 346846.938828
Epoch 11 Iteration 550: running_corrects: 2748759 running loss = 383622.583389
Epoch 11 Iteration 600: running_corrects: 3025165 running loss = 417285.817398
Epoch 11 Iteration 650: running_corrects: 3331495 running loss = 451566.974594
Epoch 11 Iteration 700: running_corrects: 3603256 running loss = 488184.806656
Epoch 11 Iteration 750: running_corrects: 3908219 running loss = 524210.978378
train Loss: 2.7468 Acc: 20.3074 F1: 0.8617
 
Epoch 11 Iteration 0: running_corrects: 8142 running loss = 1511.047363
Epoch 11 Iteration 50: running_corrects: 277244 running loss = 170034.368774
Epoch 11 Iteration 100: running_corrects: 528263 running loss = 343910.761902
Epoch 11 Iteration 150: running_corrects: 803768 running loss = 512648.692810
Epoch 11 Iteration 200: running_corrects: 1111950 running loss = 663616.949829
Epoch 11 Iteration 250: running_corrects: 1371373 running loss = 824318.036194
dev Loss: 12.8300 Acc: 20.8805 F1: 0.3222
 
Epoch 12/20
--------------------
Epoch 12 Iteration 0: running_corrects: 21754 running loss = 161.269821
Epoch 12 Iteration 50: running_corrects: 270534 running loss = 25670.769165
Epoch 12 Iteration 100: running_corrects: 544927 running loss = 53009.071899
Epoch 12 Iteration 150: running_corrects: 825377 running loss = 81608.085449
Epoch 12 Iteration 200: running_corrects: 1082797 running loss = 108190.853745
Epoch 12 Iteration 250: running_corrects: 1317474 running loss = 135820.894455
Epoch 12 Iteration 300: running_corrects: 1587679 running loss = 163474.218765
Epoch 12 Iteration 350: running_corrects: 1850216 running loss = 190687.543442
Epoch 12 Iteration 400: running_corrects: 2088669 running loss = 220762.181168
Epoch 12 Iteration 450: running_corrects: 2356515 running loss = 249415.233597
Epoch 12 Iteration 500: running_corrects: 2618479 running loss = 279450.565079
Epoch 12 Iteration 550: running_corrects: 2862499 running loss = 310813.258499
Epoch 12 Iteration 600: running_corrects: 3126993 running loss = 342598.357620
Epoch 12 Iteration 650: running_corrects: 3420153 running loss = 371942.713547
Epoch 12 Iteration 700: running_corrects: 3704088 running loss = 402570.810638
Epoch 12 Iteration 750: running_corrects: 3945028 running loss = 435294.812073
train Loss: 2.2827 Acc: 20.3804 F1: 0.8903
 
Epoch 12 Iteration 0: running_corrects: 8156 running loss = 1507.527100
Epoch 12 Iteration 50: running_corrects: 277179 running loss = 187581.208130
Epoch 12 Iteration 100: running_corrects: 528133 running loss = 383506.914368
Epoch 12 Iteration 150: running_corrects: 803596 running loss = 564393.903442
Epoch 12 Iteration 200: running_corrects: 1111711 running loss = 728111.261169
Epoch 12 Iteration 250: running_corrects: 1371056 running loss = 907284.045593
dev Loss: 14.1431 Acc: 20.8752 F1: 0.3145
 
Epoch 13/20
--------------------
Epoch 13 Iteration 0: running_corrects: 5627 running loss = 365.705963
Epoch 13 Iteration 50: running_corrects: 259672 running loss = 22485.761078
Epoch 13 Iteration 100: running_corrects: 513662 running loss = 45392.841858
Epoch 13 Iteration 150: running_corrects: 753289 running loss = 69830.718201
Epoch 13 Iteration 200: running_corrects: 1059785 running loss = 90782.888382
Epoch 13 Iteration 250: running_corrects: 1291732 running loss = 116706.742386
Epoch 13 Iteration 300: running_corrects: 1542856 running loss = 140121.771515
Epoch 13 Iteration 350: running_corrects: 1788323 running loss = 165254.807159
Epoch 13 Iteration 400: running_corrects: 2071620 running loss = 192999.360321
Epoch 13 Iteration 450: running_corrects: 2347282 running loss = 217880.283646
Epoch 13 Iteration 500: running_corrects: 2654950 running loss = 241715.522537
Epoch 13 Iteration 550: running_corrects: 2916042 running loss = 267670.680923
Epoch 13 Iteration 600: running_corrects: 3138440 running loss = 295583.483047
Epoch 13 Iteration 650: running_corrects: 3393794 running loss = 324466.656677
Epoch 13 Iteration 700: running_corrects: 3627683 running loss = 352810.902771
Epoch 13 Iteration 750: running_corrects: 3875891 running loss = 381804.946152
train Loss: 1.9889 Acc: 20.1673 F1: 0.9105
 
Epoch 13 Iteration 0: running_corrects: 8140 running loss = 1918.286011
Epoch 13 Iteration 50: running_corrects: 277110 running loss = 200085.713928
Epoch 13 Iteration 100: running_corrects: 527925 running loss = 410022.434326
Epoch 13 Iteration 150: running_corrects: 803224 running loss = 607184.670837
Epoch 13 Iteration 200: running_corrects: 1111237 running loss = 786662.327881
Epoch 13 Iteration 250: running_corrects: 1370409 running loss = 980402.582397
dev Loss: 15.2575 Acc: 20.8654 F1: 0.3200
 
Epoch 14/20
--------------------
Epoch 14 Iteration 0: running_corrects: 3578 running loss = 354.499939
Epoch 14 Iteration 50: running_corrects: 253110 running loss = 18485.009720
Epoch 14 Iteration 100: running_corrects: 526642 running loss = 38129.472519
Epoch 14 Iteration 150: running_corrects: 799657 running loss = 58234.729752
Epoch 14 Iteration 200: running_corrects: 1066295 running loss = 76483.669662
Epoch 14 Iteration 250: running_corrects: 1314200 running loss = 98123.915146
Epoch 14 Iteration 300: running_corrects: 1589436 running loss = 121035.870407
Epoch 14 Iteration 350: running_corrects: 1877492 running loss = 141343.243790
Epoch 14 Iteration 400: running_corrects: 2130775 running loss = 162810.493851
Epoch 14 Iteration 450: running_corrects: 2385826 running loss = 183581.880264
Epoch 14 Iteration 500: running_corrects: 2658501 running loss = 205313.704514
Epoch 14 Iteration 550: running_corrects: 2881776 running loss = 229363.002625
Epoch 14 Iteration 600: running_corrects: 3142133 running loss = 252100.945419
Epoch 14 Iteration 650: running_corrects: 3399163 running loss = 275128.145523
Epoch 14 Iteration 700: running_corrects: 3668166 running loss = 299888.631699
Epoch 14 Iteration 750: running_corrects: 3920846 running loss = 323898.472641
train Loss: 1.6892 Acc: 20.3962 F1: 0.9266
 
Epoch 14 Iteration 0: running_corrects: 8150 running loss = 1893.222168
Epoch 14 Iteration 50: running_corrects: 277181 running loss = 214202.216614
Epoch 14 Iteration 100: running_corrects: 528098 running loss = 435252.898743
Epoch 14 Iteration 150: running_corrects: 803551 running loss = 646577.368958
Epoch 14 Iteration 200: running_corrects: 1111649 running loss = 836573.415344
Epoch 14 Iteration 250: running_corrects: 1371024 running loss = 1037464.214905
dev Loss: 16.1110 Acc: 20.8753 F1: 0.3143
 
Epoch 15/20
--------------------
Epoch 15 Iteration 0: running_corrects: 12028 running loss = 151.540375
Epoch 15 Iteration 50: running_corrects: 257198 running loss = 16927.596527
Epoch 15 Iteration 100: running_corrects: 532341 running loss = 32166.585060
Epoch 15 Iteration 150: running_corrects: 814616 running loss = 49772.659439
Epoch 15 Iteration 200: running_corrects: 1117368 running loss = 67036.880371
Epoch 15 Iteration 250: running_corrects: 1349908 running loss = 87509.079330
Epoch 15 Iteration 300: running_corrects: 1599388 running loss = 106800.815201
Epoch 15 Iteration 350: running_corrects: 1858122 running loss = 125002.176163
Epoch 15 Iteration 400: running_corrects: 2120686 running loss = 142962.551193
Epoch 15 Iteration 450: running_corrects: 2385267 running loss = 162114.969421
Epoch 15 Iteration 500: running_corrects: 2638582 running loss = 182188.269745
Epoch 15 Iteration 550: running_corrects: 2907966 running loss = 202961.403259
Epoch 15 Iteration 600: running_corrects: 3192721 running loss = 223195.771980
Epoch 15 Iteration 650: running_corrects: 3438104 running loss = 243126.664375
Epoch 15 Iteration 700: running_corrects: 3688588 running loss = 263176.575920
Epoch 15 Iteration 750: running_corrects: 3938802 running loss = 282890.954903
train Loss: 1.4935 Acc: 20.4015 F1: 0.9378
 
Epoch 15 Iteration 0: running_corrects: 8139 running loss = 1826.388184
Epoch 15 Iteration 50: running_corrects: 276987 running loss = 221558.928345
Epoch 15 Iteration 100: running_corrects: 527777 running loss = 448099.633789
Epoch 15 Iteration 150: running_corrects: 803053 running loss = 667208.236206
Epoch 15 Iteration 200: running_corrects: 1110985 running loss = 865411.455261
Epoch 15 Iteration 250: running_corrects: 1370195 running loss = 1073545.275024
dev Loss: 16.7356 Acc: 20.8621 F1: 0.3208
 
Epoch 16/20
--------------------
Epoch 16 Iteration 0: running_corrects: 8188 running loss = 206.794281
Epoch 16 Iteration 50: running_corrects: 255498 running loss = 14717.417542
Epoch 16 Iteration 100: running_corrects: 499219 running loss = 28160.381790
Epoch 16 Iteration 150: running_corrects: 735227 running loss = 44484.470947
Epoch 16 Iteration 200: running_corrects: 986617 running loss = 59530.017853
Epoch 16 Iteration 250: running_corrects: 1246144 running loss = 77058.171356
Epoch 16 Iteration 300: running_corrects: 1532569 running loss = 92236.878082
Epoch 16 Iteration 350: running_corrects: 1839198 running loss = 108408.315002
Epoch 16 Iteration 400: running_corrects: 2103316 running loss = 126315.849472
Epoch 16 Iteration 450: running_corrects: 2358200 running loss = 144329.638870
Epoch 16 Iteration 500: running_corrects: 2643519 running loss = 163042.864899
Epoch 16 Iteration 550: running_corrects: 2922215 running loss = 179829.500832
Epoch 16 Iteration 600: running_corrects: 3169164 running loss = 198992.701698
Epoch 16 Iteration 650: running_corrects: 3426575 running loss = 217745.638405
Epoch 16 Iteration 700: running_corrects: 3654801 running loss = 236330.618034
Epoch 16 Iteration 750: running_corrects: 3933220 running loss = 255697.725731
train Loss: 1.3526 Acc: 20.3618 F1: 0.9463
 
Epoch 16 Iteration 0: running_corrects: 8148 running loss = 1848.543457
Epoch 16 Iteration 50: running_corrects: 277219 running loss = 223824.496094
Epoch 16 Iteration 100: running_corrects: 528248 running loss = 452761.642700
Epoch 16 Iteration 150: running_corrects: 803753 running loss = 671120.075317
Epoch 16 Iteration 200: running_corrects: 1111892 running loss = 865340.895935
Epoch 16 Iteration 250: running_corrects: 1371327 running loss = 1075654.860779
dev Loss: 16.7576 Acc: 20.8794 F1: 0.3197
 
Epoch 17/20
--------------------
Epoch 17 Iteration 0: running_corrects: 21754 running loss = 145.965271
Epoch 17 Iteration 50: running_corrects: 288800 running loss = 12691.191429
Epoch 17 Iteration 100: running_corrects: 529959 running loss = 26788.925652
Epoch 17 Iteration 150: running_corrects: 814135 running loss = 40618.836716
Epoch 17 Iteration 200: running_corrects: 1067857 running loss = 54526.968948
Epoch 17 Iteration 250: running_corrects: 1332861 running loss = 67641.475708
Epoch 17 Iteration 300: running_corrects: 1559929 running loss = 82907.889740
Epoch 17 Iteration 350: running_corrects: 1846627 running loss = 98278.973724
Epoch 17 Iteration 400: running_corrects: 2070090 running loss = 114424.931778
Epoch 17 Iteration 450: running_corrects: 2351155 running loss = 129930.714096
Epoch 17 Iteration 500: running_corrects: 2614027 running loss = 145975.050583
Epoch 17 Iteration 550: running_corrects: 2870750 running loss = 163482.543503
Epoch 17 Iteration 600: running_corrects: 3101368 running loss = 180908.328888
Epoch 17 Iteration 650: running_corrects: 3345009 running loss = 198392.681458
Epoch 17 Iteration 700: running_corrects: 3610919 running loss = 215784.724197
Epoch 17 Iteration 750: running_corrects: 3896772 running loss = 233066.804474
train Loss: 1.2162 Acc: 20.2782 F1: 0.9544
 
Epoch 17 Iteration 0: running_corrects: 8145 running loss = 2303.989258
Epoch 17 Iteration 50: running_corrects: 277041 running loss = 248968.325928
Epoch 17 Iteration 100: running_corrects: 527810 running loss = 500546.371338
Epoch 17 Iteration 150: running_corrects: 803088 running loss = 745904.089111
Epoch 17 Iteration 200: running_corrects: 1110989 running loss = 964625.826355
Epoch 17 Iteration 250: running_corrects: 1370173 running loss = 1198107.120178
dev Loss: 18.6539 Acc: 20.8617 F1: 0.3216
 
Epoch 18/20
--------------------
Epoch 18 Iteration 0: running_corrects: 3070 running loss = 251.321487
Epoch 18 Iteration 50: running_corrects: 233540 running loss = 13496.901802
Epoch 18 Iteration 100: running_corrects: 484455 running loss = 26165.827248
Epoch 18 Iteration 150: running_corrects: 768622 running loss = 40210.680573
Epoch 18 Iteration 200: running_corrects: 1034346 running loss = 53898.923050
Epoch 18 Iteration 250: running_corrects: 1321129 running loss = 65584.258774
Epoch 18 Iteration 300: running_corrects: 1555415 running loss = 80096.428375
Epoch 18 Iteration 350: running_corrects: 1848567 running loss = 92899.155014
Epoch 18 Iteration 400: running_corrects: 2099464 running loss = 106928.372604
Epoch 18 Iteration 450: running_corrects: 2374895 running loss = 121268.738899
Epoch 18 Iteration 500: running_corrects: 2625255 running loss = 137001.917610
Epoch 18 Iteration 550: running_corrects: 2909123 running loss = 151653.033455
Epoch 18 Iteration 600: running_corrects: 3178943 running loss = 166398.546379
Epoch 18 Iteration 650: running_corrects: 3425453 running loss = 183144.339119
Epoch 18 Iteration 700: running_corrects: 3674750 running loss = 199237.935600
Epoch 18 Iteration 750: running_corrects: 3933779 running loss = 214234.341972
train Loss: 1.1162 Acc: 20.4566 F1: 0.9589
 
Epoch 18 Iteration 0: running_corrects: 8143 running loss = 2067.949951
Epoch 18 Iteration 50: running_corrects: 277117 running loss = 245113.739868
Epoch 18 Iteration 100: running_corrects: 528006 running loss = 497218.577637
Epoch 18 Iteration 150: running_corrects: 803366 running loss = 735972.361694
Epoch 18 Iteration 200: running_corrects: 1111408 running loss = 953701.606873
Epoch 18 Iteration 250: running_corrects: 1370714 running loss = 1184259.859863
dev Loss: 18.4143 Acc: 20.8704 F1: 0.3181
 
Epoch 19/20
--------------------
Epoch 19 Iteration 0: running_corrects: 4091 running loss = 304.272003
Epoch 19 Iteration 50: running_corrects: 310872 running loss = 10224.674232
Epoch 19 Iteration 100: running_corrects: 560319 running loss = 20605.887909
Epoch 19 Iteration 150: running_corrects: 806923 running loss = 31583.876900
Epoch 19 Iteration 200: running_corrects: 1112423 running loss = 41654.281616
Epoch 19 Iteration 250: running_corrects: 1344424 running loss = 54305.629242
Epoch 19 Iteration 300: running_corrects: 1610231 running loss = 65732.899254
Epoch 19 Iteration 350: running_corrects: 1881906 running loss = 78033.682816
Epoch 19 Iteration 400: running_corrects: 2171998 running loss = 90499.589905
Epoch 19 Iteration 450: running_corrects: 2432413 running loss = 103548.739212
Epoch 19 Iteration 500: running_corrects: 2667416 running loss = 118676.659950
Epoch 19 Iteration 550: running_corrects: 2916279 running loss = 132229.296715
Epoch 19 Iteration 600: running_corrects: 3168958 running loss = 146896.597847
Epoch 19 Iteration 650: running_corrects: 3459532 running loss = 160753.133286
Epoch 19 Iteration 700: running_corrects: 3720157 running loss = 174434.819832
Epoch 19 Iteration 750: running_corrects: 3961570 running loss = 188812.593056
train Loss: 0.9913 Acc: 20.5324 F1: 0.9658
 
Epoch 19 Iteration 0: running_corrects: 8150 running loss = 2216.910400
Epoch 19 Iteration 50: running_corrects: 277178 running loss = 258884.501099
Epoch 19 Iteration 100: running_corrects: 528105 running loss = 526670.426636
Epoch 19 Iteration 150: running_corrects: 803588 running loss = 781007.097900
Epoch 19 Iteration 200: running_corrects: 1111722 running loss = 1012886.228394
Epoch 19 Iteration 250: running_corrects: 1371064 running loss = 1258224.555298
dev Loss: 19.6149 Acc: 20.8755 F1: 0.3260
 
Epoch 20/20
--------------------
Epoch 20 Iteration 0: running_corrects: 3836 running loss = 282.495636
Epoch 20 Iteration 50: running_corrects: 263045 running loss = 9808.810677
Epoch 20 Iteration 100: running_corrects: 546014 running loss = 21577.857269
Epoch 20 Iteration 150: running_corrects: 761143 running loss = 33643.192932
Epoch 20 Iteration 200: running_corrects: 996212 running loss = 46035.309021
Epoch 20 Iteration 250: running_corrects: 1246119 running loss = 58436.901390
Epoch 20 Iteration 300: running_corrects: 1535428 running loss = 70893.932289
Epoch 20 Iteration 350: running_corrects: 1787886 running loss = 83366.147285
Epoch 20 Iteration 400: running_corrects: 2065457 running loss = 95221.225258
Epoch 20 Iteration 450: running_corrects: 2328889 running loss = 109125.482552
Epoch 20 Iteration 500: running_corrects: 2592122 running loss = 120388.367096
Epoch 20 Iteration 550: running_corrects: 2868108 running loss = 133594.285057
Epoch 20 Iteration 600: running_corrects: 3103404 running loss = 146855.947884
Epoch 20 Iteration 650: running_corrects: 3372252 running loss = 158893.728050
Epoch 20 Iteration 700: running_corrects: 3651872 running loss = 170674.228889
Epoch 20 Iteration 750: running_corrects: 3906873 running loss = 183593.970238
train Loss: 0.9654 Acc: 20.4478 F1: 0.9667
 
Epoch 20 Iteration 0: running_corrects: 8146 running loss = 2350.418945
Epoch 20 Iteration 50: running_corrects: 277152 running loss = 258592.535278
Epoch 20 Iteration 100: running_corrects: 528131 running loss = 524180.556274
Epoch 20 Iteration 150: running_corrects: 803509 running loss = 785303.502075
Epoch 20 Iteration 200: running_corrects: 1111579 running loss = 1017177.446045
Epoch 20 Iteration 250: running_corrects: 1370891 running loss = 1261725.932678
dev Loss: 19.6629 Acc: 20.8726 F1: 0.3145
 
Finish Training, Best Acc:20.9317 Best F1:0.3264
[01;32mcxing95@speech10[00m:[01;34m~/4080/RL-for-QA[00m$ python train_SentPara.py exit[Kpython train_SentPara.py [15Pnvidia-smi[6Pexitpython train_SentPara.py [10Pscreen -S trainexit[Kpython train_SentPara.py [4Pcat2[C[C[C[C[4@SentPara[C[C[C[Cexit[K
exit

Script done on Sat 27 Apr 2019 04:42:33 PM EDT
